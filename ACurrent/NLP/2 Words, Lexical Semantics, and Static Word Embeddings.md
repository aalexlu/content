*January 19, 2023*

---

## Words
as dimensionality reduction (cat)

Type: abstract descriptive concept
Token: instantiation of a type

*"to be or not to be"*
- 6 tokens (to, be, or, not, to, be)
- 4 types (to, be, not, or)

How can we use types and tokens to determine vocabulary richness?
- type / token ratio

Whitespace â€“ `text.split("")`
- explosion of tokenization with this method due to punctuation
- but we typically don't want to just strip all punctuation
	- signals boundaries (sentence, clausal boundaries, parentheticals, asides)
	- some punctuation has illocutionary force (e.g. !, ?)
	- emoticons are strong signals (e.g. sentiment)
Regular Expressions
- Most tokenization algorithms (for languages delimited by whitespace) use regex to segment a string into discrete tokens.
```

```

- tokenizes following the conentions of the Penn Treebank

---

## Topic

lorem ipsum